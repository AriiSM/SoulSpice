# ğŸ–¥ï¸ SoulSpice Server Documentation

## Overview

SoulSpice is a specialized chatbot that combines expertise in psychology and cooking, providing personalized culinary advice based on emotional and psychological preferences. The project architecture uses FastAPI for the backend, with LLM integration through LM Studio and semantic search capabilities with FAISS.


## Core Components

### 1. Semantic Search Assistant

The main engine of SoulSpice is the `SemanticSearchAssistant` which:
- Retrieves relevant content from two knowledge bases (recipes and conversations)
- Generates appropriate responses using a language model
- Ensures responses are non-toxic and empathetic

### 2. TextChunkLoader

Loads pre-processed text chunks from files containing:
- Recipe data
- Conversation examples and patterns

### 3. SemanticRetriever

Uses sentence transformers and FAISS indexing to:
- Convert user questions into vector embeddings
- Find semantically similar content in knowledge bases
- Retrieve the most relevant information for generating responses

### 4. ToxicityFilter

Implements safety measures to:
- Detect potentially problematic content
- Filter out toxic responses
- Log potential issues for review

### 5. ResponseGenerator

Leverages an LLM to:
- Generate human-like, contextually appropriate responses
- Maintain a consistent tone and personality
- Adapt language based on user input

### 6. ChatService & LLMService

These services handle:
- API integration with the frontend
- Message processing and response generation
- Error handling and service availability checks

## Project Structure

```
Server/
â”œâ”€â”€ _pycache__/                    # Python cache files
â”œâ”€â”€ .deepeval/                     # DeepEval configuration files
â”œâ”€â”€ .pytest_cache/                 # PyTest cache files
â”œâ”€â”€ app/                           # Main application package
â”‚   â”œâ”€â”€ _pycache__/
â”‚   â”œâ”€â”€ api/                       # API endpoints
â”‚   â”‚   â”œâ”€â”€ _pycache__/
â”‚   â”‚   â””â”€â”€ routes.py              # FastAPI route definitions
â”‚   â”œâ”€â”€ core/                      # Core components
â”‚   â”‚   â”œâ”€â”€ _pycache__/
â”‚   â”‚   â””â”€â”€ config.py              # Application settings & config
â”‚   â”œâ”€â”€ data/                      # Data storage
â”‚   â”‚   â””â”€â”€ faiss/                 # Vector indexes
â”‚   â”‚       â”œâ”€â”€ conversations.faiss # Conversation embeddings
â”‚   â”‚       â”œâ”€â”€ parsed_conversations.txt # Conversation data
â”‚   â”‚       â”œâ”€â”€ parsed_recipes.txt  # Recipe data
â”‚   â”‚       â””â”€â”€ recipes.faiss       # Recipe embeddings
â”‚   â”œâ”€â”€ models/                    # Data models
â”‚   â”‚   â”œâ”€â”€ _pycache__/
â”‚   â”‚   â””â”€â”€ message.py             # Message schemas
â”‚   â””â”€â”€ services/                  # Business logic
â”‚       â”œâ”€â”€ _pycache__/ 
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ chat_bot_tools.py      # Core chatbot components
â”‚       â”œâ”€â”€ chat_service.py        # Chat processing logic
â”‚       â””â”€â”€ llm_service.py         # LLM integration
â”œâ”€â”€ tests/                         # Test suite
â”‚   â”œâ”€â”€ _pycache__/
â”‚   â”œâ”€â”€ .deepeval/
â”‚   â”œâ”€â”€ .pytest_cache/
â”‚   â”œâ”€â”€ evaluation_report.json     # LLM evaluation metrics results
â”‚   â””â”€â”€ test_deepeval_runner.py    # DeepEval test runner
â”œâ”€â”€ venv/                          # Virtual environment
â”œâ”€â”€ main.py                        # Server entry point
â””â”€â”€ README.md                      # Project documentation
```